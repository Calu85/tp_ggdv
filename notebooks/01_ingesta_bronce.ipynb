{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Clase 3 – Ingesta y Capa Bronce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a3d2d",
   "metadata": {},
   "source": [
    "En esta notebook se inicia la construcción del pipeline de datos meteorológicos, trabajando con los archivos crudos provistos por el SMN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573fb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importación de librerías completada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Importación de librerías completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## Configuración de paths y carpetas del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069e436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciación de carpetas del proyecto completada.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "for path in [BRONCE_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Iniciación de carpetas del proyecto completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## Lectura del archivo de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3fd630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones cargadas: 117\n",
      "Cantidad de provincias: 26\n",
      "Provincias disponibles: ['ANTARTIDA' 'BUENOS AIRES' 'CAPITAL FEDERAL' 'CATAMARCA' '' 'CHACO'\n",
      " 'CHUBUT' 'CORDOBA' 'CORRIENTES' 'ENTRE RIOS' 'FORMOSA' 'JUJUY' 'LA PAMPA'\n",
      " 'LA RIOJA' 'MENDOZA' 'MISIONES' 'NEUQUEN' 'RIO NEGRO' 'SALTA' 'SAN JUAN'\n",
      " 'SAN LUIS' 'SANTA CRUZ' 'SANTA FE' 'SANTIAGO DEL ESTERO'\n",
      " 'TIERRA DEL FUEGO' 'TUCUMAN']\n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo\n",
    "archivo_estaciones = RAW_DIR / 'estaciones' / 'estaciones_smn.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_estaciones, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()[2:]\n",
    "\n",
    "# Expresión regular para extraer campos:\n",
    "pattern = re.compile(\n",
    "    r\"^(?P<nombre>.+?)\\s{2,}(?P<provincia>.+?)\\s{2,}(?P<lat_gr>-?\\d+)\\s+(?P<lat_min>\\d+)\\s+(?P<lon_gr>-?\\d+)\\s+(?P<lon_min>\\d+)\\s+(?P<altura_m>\\d+)\\s+(?P<numero>\\d+)\\s+(?P<numero_oaci>\\S+)\\s*$\"\n",
    ")\n",
    "\n",
    "# Extraer los datos\n",
    "data = []\n",
    "for line in lines:\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        data.append(match.groupdict())\n",
    "\n",
    "# Crear DataFrame\n",
    "df_estaciones = pd.DataFrame(data)\n",
    "\n",
    "# Conversión de tipos\n",
    "df_estaciones[['lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero']] = df_estaciones[[\n",
    "    'lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero'\n",
    "]].apply(pd.to_numeric)\n",
    "\n",
    "# Cargar las provincias\n",
    "provincias_unicas = df_estaciones['provincia'].str.strip().str.upper().unique()\n",
    "\n",
    "# Imprimir la cantidad de estaciones registradas\n",
    "print(\"Estaciones cargadas:\", len(df_estaciones))\n",
    "\n",
    "# Imprimir la cantidad de provincias registradas\n",
    "print(\"Cantidad de provincias:\", len(provincias_unicas))\n",
    "\n",
    "# Imprimir las provincias\n",
    "print(\"Provincias disponibles:\", provincias_unicas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {},
   "source": [
    "## Selección de estaciones. \n",
    "\n",
    "### Para el desarrollo del trabajo se utilizarán las estaciones ubicadas en la provincia de Misiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355e73a4-ae19-4a13-9709-93f131a03792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>provincia</th>\n",
       "      <th>numero</th>\n",
       "      <th>numero_oaci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>BERNARDO DE IRIGOYEN AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87163</td>\n",
       "      <td>SATI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>IGUAZU AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87097</td>\n",
       "      <td>SARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>OBERA</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87187</td>\n",
       "      <td>SATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>POSADAS AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87178</td>\n",
       "      <td>SARP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nombre provincia  numero numero_oaci\n",
       "77  BERNARDO DE IRIGOYEN AERO  MISIONES   87163        SATI\n",
       "78                IGUAZU AERO  MISIONES   87097        SARI\n",
       "79                      OBERA  MISIONES   87187        SATO\n",
       "80               POSADAS AERO  MISIONES   87178        SARP"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingresar el nombre de la provincia con la que se va a trabajar\n",
    "provincia = 'MISIONES'\n",
    "\n",
    "df_provincia = df_estaciones[df_estaciones['provincia'].str.upper() == provincia]\n",
    "df_provincia[['nombre', 'provincia', 'numero', 'numero_oaci']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a92af-1e2b-4851-8929-6e6a8476500c",
   "metadata": {},
   "source": [
    "## Filtrar las estaciones que correspondan a la provincia seleccionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac45e6ae-4c6a-422b-80e2-3125b1a5f206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FECHA HORA TEMP HUM    PNM  DD FF       NOMBRE\n",
      "31052025    0  5.6  95 1022.3 270  6  IGUAZU AERO\n",
      "31052025    1  5.5  95 1021.9 230  9  IGUAZU AERO\n",
      "31052025    2  5.3 100 1021.8 230  6  IGUAZU AERO\n",
      "31052025    3  5.3 100 1021.5   0  0  IGUAZU AERO\n",
      "31052025    4  4.8 100 1021.4   0  0  IGUAZU AERO\n",
      "31052025    5  4.6 100 1021.3  90  6  IGUAZU AERO\n",
      "31052025    6  4.4 100 1021.5  90  7  IGUAZU AERO\n",
      "31052025    7  4.7 100 1022.1  90  9  IGUAZU AERO\n",
      "31052025    8  5.0 100 1023.2   0  0  IGUAZU AERO\n",
      "31052025    9  9.2  95 1023.4   0  0  IGUAZU AERO\n",
      "31052025   10 10.1  89 1024.2   0  0  IGUAZU AERO\n",
      "31052025   11 13.5  83 1023.8  50  6  IGUAZU AERO\n",
      "31052025   12 14.8  76 1023.1   0  0  IGUAZU AERO\n",
      "31052025   13 16.0  73 1022.0   0  0  IGUAZU AERO\n",
      "31052025   14 17.8  66 1021.2   0  0  IGUAZU AERO\n",
      "31052025   15 18.0  64 1020.6   0  0  IGUAZU AERO\n",
      "31052025   16 18.2  61 1020.4   0  0  IGUAZU AERO\n",
      "31052025   17 17.6  71 1020.6   0  0  IGUAZU AERO\n",
      "31052025   18 15.2  85 1021.3   0  0  IGUAZU AERO\n",
      "31052025   19 13.0  93 1021.7   0  0  IGUAZU AERO\n",
      "31052025   20 11.6  92 1022.1   0  0  IGUAZU AERO\n",
      "31052025   21 12.4  82 1022.2   0  0  IGUAZU AERO\n",
      "31052025   22 12.0  86 1022.3 230  9  IGUAZU AERO\n",
      "31052025   23 10.5  94 1022.8 250 11  IGUAZU AERO\n",
      "31052025    9  6.8  88 1023.4  50  4        OBERA\n",
      "31052025   15 15.8  81 1020.7 360  4        OBERA\n",
      "31052025   21  8.8  89 1022.5 360  4        OBERA\n",
      "31052025    0 10.1  88 1022.2  90  6 POSADAS AERO\n",
      "31052025    1  9.9  85 1021.9 140  4 POSADAS AERO\n",
      "31052025    2  9.3  89 1021.5 140  7 POSADAS AERO\n",
      "31052025    3  9.3  89 1021.0 110  6 POSADAS AERO\n",
      "31052025    4  9.5  89 1020.7 140  6 POSADAS AERO\n",
      "31052025    5  9.3  89 1021.0 140  7 POSADAS AERO\n",
      "31052025    6  8.8  92 1021.4 140  6 POSADAS AERO\n",
      "31052025    7  8.4  92 1021.9 110  6 POSADAS AERO\n",
      "31052025    8  8.0  95 1022.8 140  6 POSADAS AERO\n",
      "31052025    9  9.8  85 1023.2 140  7 POSADAS AERO\n",
      "31052025   10 11.6  75 1023.5 110  7 POSADAS AERO\n",
      "31052025   11 12.8  69 1023.2 110  9 POSADAS AERO\n",
      "31052025   12 14.0  66 1022.8 990  9 POSADAS AERO\n",
      "31052025   13 15.2  59 1022.3 990  9 POSADAS AERO\n",
      "31052025   14 14.6  62 1021.8 160  9 POSADAS AERO\n",
      "31052025   15 14.6  62 1021.3 140  9 POSADAS AERO\n",
      "31052025   16 14.5  61 1021.5 140 11 POSADAS AERO\n",
      "31052025   17 14.1  62 1021.8 160  9 POSADAS AERO\n",
      "31052025   18 13.3  66 1022.1 160 13 POSADAS AERO\n",
      "31052025   19 12.6  74 1023.1 160  9 POSADAS AERO\n",
      "31052025   20 12.5  76 1023.5 110  4 POSADAS AERO\n",
      "31052025   21 11.7  81 1023.7  90  6 POSADAS AERO\n",
      "31052025   22 11.5  80 1023.8 140  6 POSADAS AERO\n",
      "31052025   23 10.5  85 1024.0 160  7 POSADAS AERO\n",
      "\n",
      "Columnas: ['FECHA', 'HORA', 'TEMP', 'HUM', 'PNM', 'DD', 'FF', 'NOMBRE']\n",
      "Tipos de dato:\n",
      "FECHA      object\n",
      "HORA        Int64\n",
      "TEMP      float64\n",
      "HUM         int64\n",
      "PNM       float64\n",
      "DD          Int64\n",
      "FF          Int64\n",
      "NOMBRE     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Se selecciona una fecha para visualizar los datos\n",
    "archivo_dato = RAW_DIR / 'datohorario' / 'datohorario20250531.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_dato, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Detectar columnas separadas por múltiples espacios\n",
    "columnas = re.split(r\"\\s{2,}\", lines[0].strip())\n",
    "\n",
    "# Leer datos\n",
    "data = [\n",
    "    re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "    for line in lines[1:]\n",
    "    if len(line.strip()) > 0 and not line.isspace()\n",
    "]\n",
    "\n",
    "# Crear DataFrame con columnas originales\n",
    "df_dato = pd.DataFrame(data, columns=columnas)\n",
    "df_dato.columns = df_dato.columns.str.strip()\n",
    "df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "\n",
    "# Filtrar por estaciones\n",
    "nombres_provincia = df_provincia[\"nombre\"].str.strip().unique()\n",
    "df_provincia_dia = df_dato[df_dato[\"NOMBRE\"].isin(nombres_provincia)]\n",
    "\n",
    "# Crear copia y convertir tipos SOLO para impresión de tipos correctos\n",
    "df_tipos = df_provincia_dia.copy()\n",
    "df_tipos[\"FECHA\"] = pd.to_datetime(df_tipos[\"FECHA\"], format=\"%d%m%Y\", errors=\"coerce\").dt.date\n",
    "df_tipos[\"HORA\"] = pd.to_numeric(df_tipos[\"HORA\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df_tipos[\"TEMP\"] = pd.to_numeric(df_tipos[\"TEMP\"], errors=\"coerce\")\n",
    "df_tipos[\"HUM\"] = pd.to_numeric(df_tipos[\"HUM\"], errors=\"coerce\")\n",
    "df_tipos[\"PNM\"] = pd.to_numeric(df_tipos[\"PNM\"], errors=\"coerce\")\n",
    "df_tipos[\"DD\"] = pd.to_numeric(df_tipos[\"DD\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df_tipos[\"FF\"] = pd.to_numeric(df_tipos[\"FF\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Mostrar todos los resultados\n",
    "print(df_provincia_dia.to_string(index=False))\n",
    "print()\n",
    "print(\"Columnas:\", df_dato.columns.tolist())\n",
    "print(\"Tipos de dato:\")\n",
    "print(df_tipos.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832851a",
   "metadata": {},
   "source": [
    "## Procesamiento por estación y por fecha (con limpieza y reporte resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5af8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado.\n",
      "Días procesados: 391\n",
      "Errores al procesar archivos: 0\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta de salida si no existe\n",
    "BRONCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Buscar todos los archivos datohorario disponibles\n",
    "archivos_datos = sorted(glob(str(RAW_DIR / \"datohorario\" / \"datohorario*.txt\")))\n",
    "\n",
    "errores_globales = 0\n",
    "\n",
    "for archivo in archivos_datos:\n",
    "    try:\n",
    "        with open(archivo, encoding=\"latin1\") as f:\n",
    "            raw_lines = f.readlines()\n",
    "\n",
    "        header = raw_lines[0].strip()\n",
    "        columnas = re.split(r\"\\s{2,}\", header)\n",
    "\n",
    "        data = [\n",
    "            re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "            for line in raw_lines[1:]\n",
    "            if len(line.strip()) > 0 and not line.isspace()\n",
    "        ]\n",
    "\n",
    "        df_dato = pd.DataFrame(data, columns=columnas)\n",
    "        df_dato.columns = df_dato.columns.str.strip()\n",
    "        df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "\n",
    "        # Filtrar por estaciones según la provincia\n",
    "        df_provincia = df_dato[df_dato[\"NOMBRE\"].isin(nombres_provincia)]\n",
    "\n",
    "        # Obtener fecha\n",
    "        fecha = Path(archivo).stem.replace(\"datohorario\", \"\")\n",
    "\n",
    "        # Guardar archivos por estación\n",
    "        for nombre in nombres_provincia:\n",
    "            nombre_clean = nombre.lower().replace(\" \", \"_\")\n",
    "            df_estacion = df_provincia[df_provincia[\"NOMBRE\"] == nombre]\n",
    "\n",
    "            if not df_estacion.empty:\n",
    "                path_estacion = BRONCE_DIR / nombre_clean\n",
    "                path_estacion.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                # Archivos de salida\n",
    "                archivo_parquet = path_estacion / f\"{fecha}.parquet\"\n",
    "                archivo_csv = path_estacion / f\"{fecha}.csv\"\n",
    "                archivo_txt = path_estacion / f\"{fecha}.txt\"\n",
    "                \n",
    "                # Guardar en distintos formatos\n",
    "                df_estacion.to_parquet(archivo_parquet, index=False)\n",
    "                df_estacion.to_csv(archivo_csv, index=False)\n",
    "\n",
    "                with open(archivo_txt, \"w\", encoding=\"latin1\") as f:\n",
    "                    f.write(\"  \".join(df_estacion.columns) + \"\\n\")\n",
    "                    for _, row in df_estacion.iterrows():\n",
    "                        f.write(\"  \".join(map(str, row.values)) + \"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        errores_globales += 1\n",
    "        continue\n",
    "\n",
    "# Reporte final\n",
    "print(\"Proceso completado.\")\n",
    "print(f\"Días procesados: {len(archivos_datos)}\")\n",
    "print(f\"Errores al procesar archivos: {errores_globales}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ed668c-9c1a-4466-819f-b28b639f2432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
