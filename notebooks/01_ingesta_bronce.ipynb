{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Clase 3 – Ingesta y Capa Bronce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a3d2d",
   "metadata": {},
   "source": [
    "En esta notebook se inicia la construcción del pipeline de datos meteorológicos, trabajando con los archivos crudos provistos por el SMN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## 1. Librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "573fb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## 2. Configuración de paths y carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "069e436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "for path in [BRONCE_DIR]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## 3. Lectura del archivo de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3fd630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estaciones cargadas: 117\n"
     ]
    }
   ],
   "source": [
    "# Ruta del archivo\n",
    "archivo_estaciones = RAW_DIR / 'estaciones' / 'estaciones_smn.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_estaciones, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()[2:]\n",
    "\n",
    "# Expresión regular para extraer campos:\n",
    "pattern = re.compile(\n",
    "    r\"^(?P<nombre>.+?)\\s{2,}(?P<provincia>.+?)\\s{2,}(?P<lat_gr>-?\\d+)\\s+(?P<lat_min>\\d+)\\s+(?P<lon_gr>-?\\d+)\\s+(?P<lon_min>\\d+)\\s+(?P<altura_m>\\d+)\\s+(?P<numero>\\d+)\\s+(?P<numero_oaci>\\S+)\\s*$\"\n",
    ")\n",
    "\n",
    "# Extraer los datos\n",
    "data = []\n",
    "for line in lines:\n",
    "    match = pattern.match(line)\n",
    "    if match:\n",
    "        data.append(match.groupdict())\n",
    "\n",
    "# Crear DataFrame\n",
    "df_estaciones = pd.DataFrame(data)\n",
    "\n",
    "# Conversión de tipos\n",
    "df_estaciones[['lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero']] = df_estaciones[[\n",
    "    'lat_gr', 'lat_min', 'lon_gr', 'lon_min', 'altura_m', 'numero'\n",
    "]].apply(pd.to_numeric)\n",
    "\n",
    "print(\"Estaciones cargadas:\", len(df_estaciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {},
   "source": [
    "## 4. Selección de estaciones de Misiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0fa485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre</th>\n",
       "      <th>provincia</th>\n",
       "      <th>numero</th>\n",
       "      <th>numero_oaci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>BERNARDO DE IRIGOYEN AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87163</td>\n",
       "      <td>SATI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>IGUAZU AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87097</td>\n",
       "      <td>SARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>OBERA</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87187</td>\n",
       "      <td>SATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>POSADAS AERO</td>\n",
       "      <td>MISIONES</td>\n",
       "      <td>87178</td>\n",
       "      <td>SARP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       nombre provincia  numero numero_oaci\n",
       "77  BERNARDO DE IRIGOYEN AERO  MISIONES   87163        SATI\n",
       "78                IGUAZU AERO  MISIONES   87097        SARI\n",
       "79                      OBERA  MISIONES   87187        SATO\n",
       "80               POSADAS AERO  MISIONES   87178        SARP"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misiones = df_estaciones[df_estaciones['provincia'].str.upper() == 'MISIONES']\n",
    "df_misiones[['nombre', 'provincia', 'numero', 'numero_oaci']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545f8b9",
   "metadata": {},
   "source": [
    "## 5. Lectura de un archivo horario de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0c3af388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[HOA]  [ºC]   [%]  [hPa]  [gr] [km/hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01062024     0  14.2   82  1015.7   50   17   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01062024     1  14.3   80  1015.4  360    9   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01062024     2  14.1   86  1015.3  360    9   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01062024     3  14.1   87  1014.8  360    7   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE                                             \n",
       "0           [HOA]  [ºC]   [%]  [hPa]  [gr] [km/hr...                                                  \n",
       "1  01062024     0  14.2   82  1015.7   50   17   ...                                                  \n",
       "2  01062024     1  14.3   80  1015.4  360    9   ...                                                  \n",
       "3  01062024     2  14.1   86  1015.3  360    9   ...                                                  \n",
       "4  01062024     3  14.1   87  1014.8  360    7   ...                                                  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivo_dato = RAW_DIR / 'datohorario' / 'datohorario20240601.txt'\n",
    "df_dato = pd.read_csv(archivo_dato, sep=';', encoding='latin1')\n",
    "df_dato.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425531c",
   "metadata": {},
   "source": [
    "## 6. Limpieza básica y detección de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36cc4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reemplazados 0 valores de 9999.9 y 0 valores de -9999 por NaN.\n",
      "Valores faltantes por columna luego del reemplazo:\n",
      "FECHA     HORA  TEMP   HUM   PNM    DD    FF     NOMBRE                                                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar valores a reemplazar antes de la limpieza\n",
    "cant_9999_9 = (df_dato == 9999.9).sum().sum()\n",
    "cant_neg9999 = (df_dato == -9999).sum().sum()\n",
    "\n",
    "# Reemplazar por NaN\n",
    "df_dato.replace({9999.9: np.nan, -9999: np.nan}, inplace=True)\n",
    "\n",
    "# Imprimir resumen\n",
    "print(f\"Reemplazados {cant_9999_9} valores de 9999.9 y {cant_neg9999} valores de -9999 por NaN.\")\n",
    "print(\"Valores faltantes por columna luego del reemplazo:\")\n",
    "print(df_dato.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f03c2ef",
   "metadata": {},
   "source": [
    "## 7. Filtro por estación de Misiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1d97ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FECHA HORA TEMP HUM    PNM  DD FF       NOMBRE\n",
      "01062024    0 13.8  91 1019.6  90  7  IGUAZU AERO\n",
      "01062024    1 13.4  92 1019.5  90  7  IGUAZU AERO\n",
      "01062024    2 13.0  94 1019.0  90 11  IGUAZU AERO\n",
      "01062024    3 12.8  94 1018.3  90  9  IGUAZU AERO\n",
      "01062024    4 12.4  94 1018.3  90  7  IGUAZU AERO\n",
      "01062024    5 12.0  94 1018.7  50  4  IGUAZU AERO\n",
      "01062024    6 10.9  95 1019.1  70  4  IGUAZU AERO\n",
      "01062024    7 10.5  94 1020.5  90  6  IGUAZU AERO\n",
      "01062024    8 11.5  91 1021.3  90  4  IGUAZU AERO\n",
      "01062024    9 13.4  86 1021.4  90 17  IGUAZU AERO\n",
      "01062024   10 15.6  83 1021.6  90 13  IGUAZU AERO\n",
      "01062024   11 18.0  75 1021.4  90 15  IGUAZU AERO\n",
      "01062024   12 19.7  68 1020.7  90 17  IGUAZU AERO\n",
      "01062024   13 20.4  68 1020.0 110 11  IGUAZU AERO\n",
      "01062024   14 21.5  65 1019.1 110 13  IGUAZU AERO\n",
      "01062024   15 22.8  64 1018.3  90  9  IGUAZU AERO\n",
      "01062024   16 22.6  62 1017.9  90  9  IGUAZU AERO\n",
      "01062024   17 22.4  68 1017.8  90  9  IGUAZU AERO\n",
      "01062024   18 19.0  81 1018.1  90  9  IGUAZU AERO\n",
      "01062024   19 18.4  84 1018.3  90  6  IGUAZU AERO\n",
      "01062024   20 17.5  85 1018.5  90  4  IGUAZU AERO\n",
      "01062024   21 17.6  81 1018.5  90  7  IGUAZU AERO\n",
      "01062024   22 17.0  81 1018.1  90  6  IGUAZU AERO\n",
      "01062024   23 16.0  87 1018.1  90  7  IGUAZU AERO\n",
      "01062024    9 16.8  72 1020.4 320  4        OBERA\n",
      "01062024   15 22.8  84 1018.4  50  4        OBERA\n",
      "01062024   21 16.8  63 1017.6  50  4        OBERA\n",
      "01062024    0 16.0  85 1017.4  50  6 POSADAS AERO\n",
      "01062024    1 15.5  86 1016.9  70  7 POSADAS AERO\n",
      "01062024    2 15.5  82 1016.5  50  7 POSADAS AERO\n",
      "01062024    3 15.3  82 1016.2  50  7 POSADAS AERO\n",
      "01062024    4 14.6  86 1016.0  90  7 POSADAS AERO\n",
      "01062024    5 14.6  86 1016.3  50  7 POSADAS AERO\n",
      "01062024    6 14.4  82 1016.3  50  7 POSADAS AERO\n",
      "01062024    7 14.0  83 1017.4  50  6 POSADAS AERO\n",
      "01062024    8 13.8  86 1018.1  90  6 POSADAS AERO\n",
      "01062024    9 15.4  79 1018.4  70 11 POSADAS AERO\n",
      "01062024   10 17.6  71 1018.6  50 13 POSADAS AERO\n",
      "01062024   11 19.4  65 1018.8  20 13 POSADAS AERO\n",
      "01062024   12 21.0  64 1018.5  20 13 POSADAS AERO\n",
      "01062024   13 22.6  62 1017.6  20  7 POSADAS AERO\n",
      "01062024   14 24.4  55 1016.6  20 11 POSADAS AERO\n",
      "01062024   15 24.8  54 1016.0  50  9 POSADAS AERO\n",
      "01062024   16 24.4  56 1015.5  20 13 POSADAS AERO\n",
      "01062024   17 24.2  57 1015.3  20 11 POSADAS AERO\n",
      "01062024   18 23.8  59 1015.4  20  9 POSADAS AERO\n",
      "01062024   19 20.2  77 1015.9  70  7 POSADAS AERO\n",
      "01062024   20 19.4  79 1016.3  90  9 POSADAS AERO\n",
      "01062024   21 18.9  81 1016.5  70  9 POSADAS AERO\n",
      "01062024   22 18.7  80 1016.5  70  9 POSADAS AERO\n",
      "01062024   23 18.3  80 1016.6  50 11 POSADAS AERO\n"
     ]
    }
   ],
   "source": [
    "archivo_dato = RAW_DIR / 'datohorario' / 'datohorario20240601.txt'\n",
    "\n",
    "# Leer todas las líneas, omitiendo las dos primeras (encabezado y unidades)\n",
    "with open(archivo_dato, \"r\", encoding=\"latin1\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Detectar columnas separadas por múltiples espacios\n",
    "columnas = re.split(r\"\\s{2,}\", lines[0].strip())\n",
    "\n",
    "# Leer datos\n",
    "data = [\n",
    "    re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "    for line in lines[1:]\n",
    "    if len(line.strip()) > 0 and not line.isspace()\n",
    "]\n",
    "\n",
    "df_dato = pd.DataFrame(data, columns=columnas)\n",
    "\n",
    "# Filtrar por estaciones de Misiones\n",
    "df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "nombres_misiones = df_misiones[\"nombre\"].str.strip().unique()\n",
    "df_misiones_dia = df_dato[df_dato[\"NOMBRE\"].isin(nombres_misiones)]\n",
    "#print(df_misiones_dia.head())\n",
    "\n",
    "# Mostrar todos los resultados (sin limitar con .head())\n",
    "print(df_misiones_dia.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63370d18",
   "metadata": {},
   "source": [
    "## 8. Exportación de archivos filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f344ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado: 20240601_bernardo_de_irigoyen_aero.csv y 20240601_bernardo_de_irigoyen_aero.parquet\n",
      "Exportado: 20240601_iguazu_aero.csv y 20240601_iguazu_aero.parquet\n",
      "Exportado: 20240601_obera.csv y 20240601_obera.parquet\n",
      "Exportado: 20240601_posadas_aero.csv y 20240601_posadas_aero.parquet\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta de salida si no existe\n",
    "BRONCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Definir la fecha (puede venir del nombre del archivo)\n",
    "fecha = \"20240601\"  # o extraela dinámicamente si lo preferís\n",
    "\n",
    "# Iterar por cada estación de Misiones\n",
    "for nombre in nombres_misiones:\n",
    "    nombre_clean = nombre.lower().replace(' ', '_')\n",
    "    \n",
    "    # Filtrar las filas de esa estación\n",
    "    df_estacion = df_misiones_dia[df_misiones_dia[\"NOMBRE\"] == nombre]\n",
    "    \n",
    "    # Definir archivos de salida con fecha al inicio\n",
    "    salida_csv = BRONCE_DIR / f'{fecha}_{nombre_clean}.csv'\n",
    "    salida_parquet = BRONCE_DIR / f'{fecha}_{nombre_clean}.parquet'\n",
    "    \n",
    "    # Exportar\n",
    "    df_estacion.to_csv(salida_csv, index=False)\n",
    "    df_estacion.to_parquet(salida_parquet, index=False)\n",
    "    \n",
    "    print(f\"Exportado: {salida_csv.name} y {salida_parquet.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53b561",
   "metadata": {},
   "source": [
    "## Próximos pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7c349",
   "metadata": {},
   "source": [
    "- Extender este proceso a más días o meses.\n",
    "- Organizar las salidas por carpeta `/bronce/{estacion}/{año}/`.\n",
    "- Documentar el diccionario de variables en `metadata/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832851a",
   "metadata": {},
   "source": [
    "### 🔟 Paso 9 – Procesamiento por estación y por fecha (con limpieza y reporte resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5af8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Proceso completado.\n",
      "Días procesados: 391\n",
      "Errores al procesar archivos: 391\n",
      "Valores reemplazados: 0 de 9999.9 y 0 de -9999\n",
      "Total de valores nulos luego de limpieza: 260790\n"
     ]
    }
   ],
   "source": [
    "# Buscar todos los archivos datohorario disponibles\n",
    "archivos_datos = sorted(glob(str(RAW_DIR / \"datohorario\" / \"datohorario*.txt\")))\n",
    "\n",
    "errores_globales = 0\n",
    "nulos_total = 0\n",
    "reemplazados_9999_9 = 0\n",
    "reemplazados_neg9999 = 0\n",
    "detalle_nulos = []\n",
    "\n",
    "for archivo in archivos_datos:\n",
    "    try:\n",
    "        with open(archivo, encoding=\"latin1\") as f:\n",
    "            raw_lines = f.readlines()\n",
    "\n",
    "        header = raw_lines[0].strip()\n",
    "        columnas = re.split(r\"\\s{2,}\", header)\n",
    "\n",
    "        data = [\n",
    "            re.split(r\"\\s{2,}\", line.strip(), maxsplit=len(columnas)-1)\n",
    "            for line in raw_lines[1:]\n",
    "            if len(line.strip()) > 0 and not line.isspace()\n",
    "        ]\n",
    "\n",
    "        df_dato = pd.DataFrame(data, columns=columnas)\n",
    "        df_dato.columns = df_dato.columns.str.strip()\n",
    "        df_dato[\"NOMBRE\"] = df_dato[\"NOMBRE\"].str.strip()\n",
    "\n",
    "        # Convertir columnas numéricas si es posible\n",
    "        for col in df_dato.columns:\n",
    "            try:\n",
    "                df_dato[col] = pd.to_numeric(df_dato[col])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Conteo previo de valores a reemplazar\n",
    "        cant_9999_9 = (df_dato == 9999.9).sum().sum()\n",
    "        cant_neg9999 = (df_dato == -9999).sum().sum()\n",
    "\n",
    "        reemplazados_9999_9 += cant_9999_9\n",
    "        reemplazados_neg9999 += cant_neg9999\n",
    "\n",
    "        # Reemplazo\n",
    "        df_dato.replace({9999.9: np.nan, -9999: np.nan}, inplace=True)\n",
    "\n",
    "        # Contar nulos\n",
    "        nulos_total += df_dato.isna().sum().sum()\n",
    "\n",
    "        # Filtrar por estaciones de Misiones\n",
    "        df_misiones = df_dato[df_dato[\"NOMBRE\"].isin(nombres_misiones)]\n",
    "\n",
    "        # Obtener fecha\n",
    "        fecha = Path(archivo).stem.replace(\"datohorario\", \"\")\n",
    "\n",
    "        # Guardar archivos por estación + generar detalle\n",
    "        for nombre in nombres_misiones:\n",
    "            nombre_clean = nombre.lower().replace(\" \", \"_\")\n",
    "            df_estacion = df_misiones[df_misiones[\"NOMBRE\"] == nombre]\n",
    "\n",
    "            if not df_estacion.empty:\n",
    "                path_estacion = BRONCE_DIR / nombre_clean\n",
    "                path_estacion.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                df_estacion.to_parquet(path_estacion / f\"{fecha}.parquet\", index=False)\n",
    "                df_estacion.to_csv(path_estacion / f\"{fecha}.csv\", index=False)\n",
    "\n",
    "                # Registro de nulos por estación\n",
    "                nulos_por_col = df_estacion.isna().sum()\n",
    "                detalle_nulos.append({\n",
    "                    \"archivo\": Path(archivo).name,\n",
    "                    \"fecha\": fecha,\n",
    "                    \"estacion\": nombre,\n",
    "                    \"nulos_totales\": int(nulos_por_col.sum()),\n",
    "                    \"nulos_por_columna\": json.dumps(nulos_por_col[nulos_por_col > 0].to_dict())\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        errores_globales += 1\n",
    "        continue\n",
    "\n",
    "# Reporte final\n",
    "print(\"✅ Proceso completado.\")\n",
    "print(f\"Días procesados: {len(archivos_datos)}\")\n",
    "print(f\"Errores al procesar archivos: {errores_globales}\")\n",
    "print(f\"Valores reemplazados: {reemplazados_9999_9} de 9999.9 y {reemplazados_neg9999} de -9999\")\n",
    "print(f\"Total de valores nulos luego de limpieza: {nulos_total}\")\n",
    "\n",
    "# Guardar resumen general\n",
    "reporte = {\n",
    "    \"dias_procesados\": [len(archivos_datos)],\n",
    "    \"errores\": [errores_globales],\n",
    "    \"reemplazados_9999_9\": [reemplazados_9999_9],\n",
    "    \"reemplazados_-9999\": [reemplazados_neg9999],\n",
    "    \"valores_nulos_totales\": [nulos_total],\n",
    "}\n",
    "df_reporte = pd.DataFrame(reporte)\n",
    "df_reporte.to_csv(BRONCE_DIR / \"reporte_resumen.csv\", index=False)\n",
    "\n",
    "# Guardar detalle de nulos por archivo y estación\n",
    "df_detalle = pd.DataFrame(detalle_nulos)\n",
    "df_detalle.to_csv(BRONCE_DIR / \"reporte_nulos_detalle.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
