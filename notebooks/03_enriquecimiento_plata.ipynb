{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303ce6d",
   "metadata": {},
   "source": [
    "# Clase 5 ‚Äì Enriquecimiento de la capa Plata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a3d2d",
   "metadata": {},
   "source": [
    "En esta notebook se\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c87778",
   "metadata": {},
   "source": [
    "## Importar las librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573fb540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importaci√≥n de librer√≠as completada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajustar el ancho m√°ximo para impresi√≥n en consola\n",
    "pd.set_option('display.max_columns', None)  # Mostrar todas las columnas\n",
    "pd.set_option('display.width', 300)         # Ajustar a un ancho suficiente en consola\n",
    "pd.set_option('display.max_colwidth', None) # Evitar recortes en contenido de celdas\n",
    "\n",
    "print(\"Importaci√≥n de librer√≠as completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201f0b",
   "metadata": {},
   "source": [
    "## Configuraci√≥n de paths y carpetas del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "069e436c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciaci√≥n de carpetas del proyecto completada.\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('..').resolve()\n",
    "RAW_DIR = BASE_DIR / 'data' / 'raw'\n",
    "BRONCE_DIR = BASE_DIR / 'data' / 'bronce'\n",
    "PLATA_DIR = Path(\"../data/plata\")\n",
    "\n",
    "archivo_plata = PLATA_DIR / \"misiones_plata.csv\"\n",
    "archivo_horario = PLATA_DIR / \"misiones_horario.csv\"\n",
    "\n",
    "print(\"Iniciaci√≥n de carpetas del proyecto completada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cba45b",
   "metadata": {},
   "source": [
    "## Carga del dataset y verificaci√≥n de estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3fd630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset diario cargado correctamente\n",
      "‚úÖ Dataset horario cargado correctamente\n",
      "\n",
      "üìå Dataset diario:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1095 entries, 0 to 1094\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ESTACION              1095 non-null   object        \n",
      " 1   FECHA                 1095 non-null   datetime64[ns]\n",
      " 2   TEMP_MEAN             1095 non-null   float64       \n",
      " 3   TEMP_MIN              1095 non-null   float64       \n",
      " 4   TEMP_MAX              1095 non-null   float64       \n",
      " 5   PNM_MEAN              1095 non-null   float64       \n",
      " 6   PNM_MIN               1095 non-null   float64       \n",
      " 7   PNM_MAX               1095 non-null   float64       \n",
      " 8   HUM_MEAN              1095 non-null   float64       \n",
      " 9   HUM_MIN               1095 non-null   int64         \n",
      " 10  HUM_MAX               1095 non-null   int64         \n",
      " 11  WIND_DIR_MEAN         1095 non-null   float64       \n",
      " 12  WIND_DIR_MIN          1095 non-null   int64         \n",
      " 13  WIND_DIR_MAX          1095 non-null   int64         \n",
      " 14  WIND_SPEED_MEAN       1095 non-null   float64       \n",
      " 15  WIND_SPEED_MIN        1095 non-null   int64         \n",
      " 16  WIND_SPEED_MAX        1095 non-null   int64         \n",
      " 17  TEMP_MEAN_NORM        1095 non-null   float64       \n",
      " 18  PNM_MEAN_NORM         1095 non-null   float64       \n",
      " 19  HUM_MEAN_NORM         1095 non-null   float64       \n",
      " 20  WIND_DIR_MEAN_NORM    1095 non-null   float64       \n",
      " 21  WIND_SPEED_MEAN_NORM  1095 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(14), int64(6), object(1)\n",
      "memory usage: 188.3+ KB\n",
      "\n",
      "\n",
      "      ESTACION      FECHA  TEMP_MEAN  TEMP_MIN  TEMP_MAX  PNM_MEAN  PNM_MIN  PNM_MAX  HUM_MEAN  HUM_MIN  HUM_MAX  WIND_DIR_MEAN  WIND_DIR_MIN  WIND_DIR_MAX  WIND_SPEED_MEAN  WIND_SPEED_MIN  WIND_SPEED_MAX  TEMP_MEAN_NORM  PNM_MEAN_NORM  HUM_MEAN_NORM  WIND_DIR_MEAN_NORM  WIND_SPEED_MEAN_NORM\n",
      "0  IGUAZU AERO 2024-06-01       16.3      10.5      22.8    1019.3   1017.8   1021.6      82.4       62       95           89.2            50           110              8.8               4              17        0.405797       0.599303       0.707641            0.187275              0.256410\n",
      "1  IGUAZU AERO 2024-06-02       19.7      14.0      28.8    1017.1   1015.0   1018.7      77.6       51       91           80.0            20           110              8.2               4              15        0.528986       0.522648       0.627907            0.159664              0.234432\n",
      "2  IGUAZU AERO 2024-06-03       20.2      16.4      25.6    1019.3   1018.0   1021.4      82.7       62       98          172.5            70           270              7.8               4              17        0.547101       0.599303       0.712625            0.437275              0.219780\n",
      "3  IGUAZU AERO 2024-06-04       20.1      14.6      27.3    1018.5   1016.4   1020.2      83.6       61       99          122.7             0           990              6.2               0              11        0.543478       0.571429       0.727575            0.287815              0.161172\n",
      "4  IGUAZU AERO 2024-06-05       21.5      18.2      27.2    1018.2   1015.9   1020.7      80.0       56       94           81.7            20           110              8.0               4              13        0.594203       0.560976       0.667774            0.164766              0.227106\n",
      "\n",
      "üìå Dataset horario:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19656 entries, 0 to 19655\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   FECHA             19656 non-null  object        \n",
      " 1   HORA              19656 non-null  int64         \n",
      " 2   TEMP              19656 non-null  float64       \n",
      " 3   HUM               19656 non-null  int64         \n",
      " 4   PNM               19656 non-null  float64       \n",
      " 5   DD                19656 non-null  int64         \n",
      " 6   FF                19656 non-null  int64         \n",
      " 7   NOMBRE            19656 non-null  object        \n",
      " 8   estacion_archivo  19656 non-null  int64         \n",
      " 9   FECHA_HORA        19656 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(5), object(2)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "\n",
      "        FECHA  HORA  TEMP  HUM     PNM   DD  FF NOMBRE  estacion_archivo          FECHA_HORA\n",
      "0  2025-06-13     9  11.8   79  1019.5   50   4  OBERA          20250613 2025-06-13 09:00:00\n",
      "1  2025-06-13    15  19.8   92  1020.1   50   4  OBERA          20250613 2025-06-13 15:00:00\n",
      "2  2025-06-13    21  15.8   81  1017.7   90   4  OBERA          20250613 2025-06-13 21:00:00\n",
      "3  2025-04-24     9  19.8   98  1007.1  360   4  OBERA          20250424 2025-04-24 09:00:00\n",
      "4  2025-04-24    15  24.8   70  1013.7  360   4  OBERA          20250424 2025-04-24 15:00:00\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset diario\n",
    "try:\n",
    "    df_plata = pd.read_csv(archivo_plata, parse_dates=[\"FECHA\"])\n",
    "    print(\"Dataset diario cargado correctamente\")\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo diario no fue encontrado\")\n",
    "\n",
    "# Cargar el dataset horario\n",
    "try:\n",
    "    df_horario = pd.read_csv(archivo_horario, parse_dates=[\"FECHA_HORA\"])\n",
    "    print(\"Dataset horario cargado correctamente\")\n",
    "except FileNotFoundError:\n",
    "    print(\"El archivo horario no fue encontrado\")\n",
    "\n",
    "# Vista preliminar\n",
    "print(\"\\n Dataset diario:\")\n",
    "df_plata.info()\n",
    "print(\"\\n\")\n",
    "print(df_plata.head())\n",
    "\n",
    "print(\"\\n Dataset horario:\")\n",
    "df_horario.info()\n",
    "print(\"\\n\")\n",
    "print(df_horario.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209b877-0cff-4dc7-ba04-d9ed38525d7a",
   "metadata": {},
   "source": [
    "Este paso permite validar la estructura general, tipos de datos y posibles columnas faltantes tanto en el dataset diario como en el horario. Si todo est√° correcto, avanzaremos con el enriquecimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de26",
   "metadata": {},
   "source": [
    "## Detecci√≥n y an√°lisis de fechas faltantes\n",
    "\n",
    "Una vez verificada la estructura del dataset diario, procedemos a identificar si existen fechas faltantes en la serie por estaci√≥n. \n",
    "\n",
    "Esto nos permitir√° decidir estrategias para tratar los d√≠as sin registros, como imputaci√≥n o exclusi√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "392108e6-7ec0-42ce-a42f-5f1c440573fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Fechas faltantes exportadas a: ../data/plata/fechas_faltantes.txt\n",
      "    ESTACION      FECHA\n",
      "4      OBERA 2024-06-02\n",
      "25     OBERA 2024-06-09\n",
      "46     OBERA 2024-06-16\n",
      "88     OBERA 2024-06-30\n",
      "109    OBERA 2024-07-07\n"
     ]
    }
   ],
   "source": [
    "# Generar el rango completo de fechas esperadas\n",
    "fechas_totales = pd.date_range(start=df_plata['FECHA'].min(), end=df_plata['FECHA'].max(), freq='D')\n",
    "\n",
    "# Obtener todas las combinaciones posibles de fecha y estaci√≥n\n",
    "estaciones = df_plata['ESTACION'].unique()\n",
    "index_completo = pd.MultiIndex.from_product([fechas_totales, estaciones], names=['FECHA', 'ESTACION'])\n",
    "\n",
    "# Reindexar para insertar NaNs expl√≠citos en las fechas faltantes\n",
    "df_plata = df_plata.set_index(['FECHA', 'ESTACION']).reindex(index_completo).reset_index()\n",
    "\n",
    "# Verificar fechas faltantes (para exportar listado)\n",
    "faltantes = df_plata[df_plata.isnull().any(axis=1)][['ESTACION', 'FECHA']]\n",
    "\n",
    "if not faltantes.empty:\n",
    "    faltantes.to_csv(PLATA_DIR / \"fechas_faltantes.txt\", index=False, sep='\\t')\n",
    "    print(\"Fechas faltantes exportadas a:\", PLATA_DIR / \"fechas_faltantes.txt\")\n",
    "else:\n",
    "    print(\"No se encontraron fechas faltantes\")\n",
    "\n",
    "# Mostrar ejemplo si hay faltantes\n",
    "print(faltantes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b85704-5591-470e-a46e-a43346980116",
   "metadata": {},
   "source": [
    "Esta estrategia asegura que cada estaci√≥n tenga una fila para cada fecha del rango, incluso si originalmente no hab√≠a registros ese d√≠a. Esto deja los valores faltantes como `NaN`, que luego se tratar√°n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c913c6-b13f-416a-8d06-ce3e48fc53dc",
   "metadata": {},
   "source": [
    "## Tratamiento de valores nulos\n",
    "\n",
    "Luego de verificar fechas faltantes, analizamos los valores `NaN` dentro del dataset actual para decidir estrategias de imputaci√≥n o tratamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f65cc-3a3a-4170-908f-3902830d2b18",
   "metadata": {},
   "source": [
    "### Tratamiento de datos faltantes en el dataset diario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4bfbac3-51b4-4b6b-8ceb-920aead48862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos por columna:\n",
      "FECHA                    0\n",
      "ESTACION                 0\n",
      "TEMP_MEAN               90\n",
      "TEMP_MIN                90\n",
      "TEMP_MAX                90\n",
      "PNM_MEAN                90\n",
      "PNM_MIN                 90\n",
      "PNM_MAX                 90\n",
      "HUM_MEAN                90\n",
      "HUM_MIN                 90\n",
      "HUM_MAX                 90\n",
      "WIND_DIR_MEAN           90\n",
      "WIND_DIR_MIN            90\n",
      "WIND_DIR_MAX            90\n",
      "WIND_SPEED_MEAN         90\n",
      "WIND_SPEED_MIN          90\n",
      "WIND_SPEED_MAX          90\n",
      "TEMP_MEAN_NORM          90\n",
      "PNM_MEAN_NORM           90\n",
      "HUM_MEAN_NORM           90\n",
      "WIND_DIR_MEAN_NORM      90\n",
      "WIND_SPEED_MEAN_NORM    90\n",
      "dtype: int64\n",
      "\n",
      "Porcentaje de valores nulos:\n",
      "FECHA                   0.00\n",
      "ESTACION                0.00\n",
      "TEMP_MEAN               7.59\n",
      "TEMP_MIN                7.59\n",
      "TEMP_MAX                7.59\n",
      "PNM_MEAN                7.59\n",
      "PNM_MIN                 7.59\n",
      "PNM_MAX                 7.59\n",
      "HUM_MEAN                7.59\n",
      "HUM_MIN                 7.59\n",
      "HUM_MAX                 7.59\n",
      "WIND_DIR_MEAN           7.59\n",
      "WIND_DIR_MIN            7.59\n",
      "WIND_DIR_MAX            7.59\n",
      "WIND_SPEED_MEAN         7.59\n",
      "WIND_SPEED_MIN          7.59\n",
      "WIND_SPEED_MAX          7.59\n",
      "TEMP_MEAN_NORM          7.59\n",
      "PNM_MEAN_NORM           7.59\n",
      "HUM_MEAN_NORM           7.59\n",
      "WIND_DIR_MEAN_NORM      7.59\n",
      "WIND_SPEED_MEAN_NORM    7.59\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Visualizar cantidad de nulos por columna\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df_plata.isnull().sum())\n",
    "\n",
    "# Calcular porcentaje de nulos por columna\n",
    "porcentaje_nulos = df_plata.isnull().mean() * 100\n",
    "print(\"\\nPorcentaje de valores nulos:\")\n",
    "print(porcentaje_nulos.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8a240-a6f6-4609-b13c-0ea3aea43a1c",
   "metadata": {},
   "source": [
    "Una vez identificadas las columnas afectadas, proponemos distintas estrategias para completar los datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e8c214-e0d0-4a2a-b7f6-6905872c9356",
   "metadata": {},
   "source": [
    "### Relleno con forward fill por estaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b407236-2e12-4451-9c17-492b77e80fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de datos tras forward fill:\n",
      "        FECHA     ESTACION  TEMP_MEAN  TEMP_MIN  TEMP_MAX  PNM_MEAN  PNM_MIN  PNM_MAX  HUM_MEAN  HUM_MIN  HUM_MAX  WIND_DIR_MEAN  WIND_DIR_MIN  WIND_DIR_MAX  WIND_SPEED_MEAN  WIND_SPEED_MIN  WIND_SPEED_MAX  TEMP_MEAN_NORM  PNM_MEAN_NORM  HUM_MEAN_NORM  WIND_DIR_MEAN_NORM  WIND_SPEED_MEAN_NORM\n",
      "0  2024-06-01  IGUAZU AERO       16.3      10.5      22.8    1019.3   1017.8   1021.6      82.4     62.0     95.0           89.2          50.0         110.0              8.8             4.0            17.0        0.405797       0.599303       0.707641            0.187275              0.256410\n",
      "3  2024-06-02  IGUAZU AERO       19.7      14.0      28.8    1017.1   1015.0   1018.7      77.6     51.0     91.0           80.0          20.0         110.0              8.2             4.0            15.0        0.528986       0.522648       0.627907            0.159664              0.234432\n",
      "6  2024-06-03  IGUAZU AERO       20.2      16.4      25.6    1019.3   1018.0   1021.4      82.7     62.0     98.0          172.5          70.0         270.0              7.8             4.0            17.0        0.547101       0.599303       0.712625            0.437275              0.219780\n",
      "9  2024-06-04  IGUAZU AERO       20.1      14.6      27.3    1018.5   1016.4   1020.2      83.6     61.0     99.0          122.7           0.0         990.0              6.2             0.0            11.0        0.543478       0.571429       0.727575            0.287815              0.161172\n",
      "12 2024-06-05  IGUAZU AERO       21.5      18.2      27.2    1018.2   1015.9   1020.7      80.0     56.0     94.0           81.7          20.0         110.0              8.0             4.0            13.0        0.594203       0.560976       0.667774            0.164766              0.227106\n"
     ]
    }
   ],
   "source": [
    "# Ordenar por estaci√≥n y fecha para aplicar forward fill correctamente\n",
    "df_plata_ffill = df_plata.sort_values(['ESTACION', 'FECHA']).copy()\n",
    "df_plata_ffill.update(df_plata.groupby('ESTACION').ffill())\n",
    "\n",
    "# Vista previa de ejemplo tras forward fill\n",
    "print(\"\\nEjemplo de datos tras forward fill:\")\n",
    "print(df_plata_ffill.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacaf95f-a649-4971-b4ee-9c042fe1db11",
   "metadata": {},
   "source": [
    "### Imputaci√≥n con la media de cada estaci√≥n (solo para columnas num√©ricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6159b92c-f4f2-4554-8400-2d043628374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores nulos despu√©s de imputaci√≥n con medias:\n",
      "TEMP_MEAN          0\n",
      "PNM_MEAN           0\n",
      "HUM_MEAN           0\n",
      "WIND_SPEED_MEAN    0\n",
      "WIND_DIR_MEAN      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imputar con la media por estaci√≥n\n",
    "columnas_a_imputar = ['TEMP_MEAN', 'PNM_MEAN', 'HUM_MEAN', 'WIND_SPEED_MEAN', 'WIND_DIR_MEAN']\n",
    "\n",
    "for col in columnas_a_imputar:\n",
    "    df_plata_ffill[col] = df_plata_ffill.groupby('ESTACION')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "# Verificar resultado tras imputaci√≥n\n",
    "print(\"\\nValores nulos despu√©s de imputaci√≥n con medias:\")\n",
    "print(df_plata_ffill[columnas_a_imputar].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3908a838-a9c0-4c8f-b1f5-b6005cfa8706",
   "metadata": {},
   "source": [
    "Estas estrategias permiten garantizar que las variables derivadas a construir se basen en datos consistentes, sin afectar la distribuci√≥n ni introducir sesgos evidentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e25e56-6de6-47c7-9d84-967dd5acbdd0",
   "metadata": {},
   "source": [
    "### Tratamiento de datos faltantes en el dataset horario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dbd7603-b5fb-446f-9f57-f12b36817782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diferencia de tama√±o (horas originales vs completadas por horario habitual):\n",
      "Original: 19656\n",
      "Completo: 20145\n",
      "\n",
      "Ejemplo de datos horarios con NaN insertados:\n",
      "   NOMBRE          FECHA_HORA FECHA  HORA  TEMP  HUM  PNM  DD  FF  estacion_archivo\n",
      "3   OBERA 2024-06-02 09:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "4   OBERA 2024-06-02 15:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "5   OBERA 2024-06-02 21:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "11  OBERA 2024-06-04 21:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "16  OBERA 2024-06-06 15:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n"
     ]
    }
   ],
   "source": [
    "# Detectar horarios reales de cada estaci√≥n\n",
    "df_horario['HORA'] = df_horario['FECHA_HORA'].dt.hour\n",
    "horarios_por_estacion = df_horario.groupby('NOMBRE')['HORA'].value_counts().unstack(fill_value=0)\n",
    "horarios_mas_frecuentes = horarios_por_estacion.idxmax(axis=1)\n",
    "\n",
    "# Detectar horarios outlier (menos del 5% de los d√≠as)\n",
    "outliers_horarios = {}\n",
    "for estacion in horarios_por_estacion.index:\n",
    "    total_dias = df_horario[df_horario['NOMBRE'] == estacion]['FECHA_HORA'].dt.date.nunique()\n",
    "    outliers = horarios_por_estacion.loc[estacion][\n",
    "        horarios_por_estacion.loc[estacion] / total_dias < 0.05\n",
    "    ].index.tolist()\n",
    "    if outliers:\n",
    "        outliers_horarios[estacion] = outliers\n",
    "\n",
    "# Crear index completo por estaci√≥n y sus horarios t√≠picos\n",
    "df_horario['FECHA'] = df_horario['FECHA_HORA'].dt.floor('D')\n",
    "estaciones_h = df_horario['NOMBRE'].unique()\n",
    "fecha_h_min = df_horario['FECHA'].min()\n",
    "fecha_h_max = df_horario['FECHA'].max()\n",
    "rango_fechas = pd.date_range(start=fecha_h_min, end=fecha_h_max, freq='D')\n",
    "\n",
    "# Crear combinaciones v√°lidas por estaci√≥n\n",
    "porcentaje_frecuencia = 0.05 # al menos en 5% de los d√≠as\n",
    "\n",
    "index_completo_personalizado = []\n",
    "for estacion in estaciones_h:\n",
    "    total_dias_estacion = df_horario[df_horario['NOMBRE'] == estacion]['FECHA'].nunique()\n",
    "    horas_validas = horarios_por_estacion.columns[\n",
    "        (horarios_por_estacion.loc[estacion] / total_dias_estacion) >= porcentaje_frecuencia  \n",
    "    ].tolist()\n",
    "\n",
    "    for fecha in rango_fechas:\n",
    "        for hora in horas_validas:\n",
    "            index_completo_personalizado.append((estacion, pd.Timestamp(fecha + pd.Timedelta(hours=hora))))\n",
    "\n",
    "index_completo_h = pd.MultiIndex.from_tuples(index_completo_personalizado, names=['NOMBRE', 'FECHA_HORA'])\n",
    "\n",
    "# Reindexar para insertar valores faltantes en los horarios esperados √∫nicamente\n",
    "df_horario_completo = df_horario.set_index(['NOMBRE', 'FECHA_HORA']).reindex(index_completo_h).reset_index()\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(\"\\nDiferencia de tama√±o (horas originales vs completadas por horario habitual):\")\n",
    "print(\"Original:\", len(df_horario))\n",
    "print(\"Completo:\", len(df_horario_completo))\n",
    "print(\"\\nEjemplo de datos horarios con NaN insertados:\")\n",
    "print(df_horario_completo[df_horario_completo.isnull().any(axis=1)].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe64ec-63a1-4df4-99b5-7b3a8f844f5f",
   "metadata": {},
   "source": [
    "### Mostrar horarios outliers detectados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3efa97cf-8e8b-4e6d-bf2c-5f77410e2855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Registros reales en horarios at√≠picos:\n",
      " - OBERA: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23]\n",
      "\n",
      " Archivo exportado con registros reales en horarios at√≠picos:\n",
      "../data/plata/registros_horarios_atipicos.csv\n"
     ]
    }
   ],
   "source": [
    "# Visualizar registros reales en horarios at√≠picos detectados\n",
    "print(\"\\n Registros reales en horarios at√≠picos:\")\n",
    "for estacion, horas in outliers_horarios.items():\n",
    "    print(f\" - {estacion}: {horas}\")\n",
    "\n",
    "# Registrar los registros reales que ocurren en horarios at√≠picos\n",
    "df_outliers_registros = []\n",
    "for estacion, horas_outlier in outliers_horarios.items():\n",
    "    registros_outlier = df_horario[\n",
    "        (df_horario['NOMBRE'] == estacion) &\n",
    "        (df_horario['HORA'].isin(horas_outlier))\n",
    "    ]\n",
    "    if not registros_outlier.empty:\n",
    "        df_outliers_registros.append(registros_outlier)\n",
    "\n",
    "# Concatenar y exportar si hay registros\n",
    "if df_outliers_registros:\n",
    "    df_outliers_concat = pd.concat(df_outliers_registros)\n",
    "    archivo_outliers = PLATA_DIR / \"registros_horarios_atipicos.csv\"\n",
    "    df_outliers_concat.to_csv(archivo_outliers, index=False)\n",
    "    print(\"\\n Archivo exportado con registros reales en horarios at√≠picos:\")\n",
    "    print(archivo_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ab9e1-38b0-422b-8ac8-fabee6b2cc05",
   "metadata": {},
   "source": [
    "## Exportar datasets intermedios (antes de procesar los NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e123bf3d-a7ba-4ed6-b638-889d892267bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos generados correctamente\n"
     ]
    }
   ],
   "source": [
    "# Exportar datasets intermedios (si se desea conservar)\n",
    "df_plata.to_csv(PLATA_DIR / \"misiones_plata_con_nan.csv\", index=False)\n",
    "df_plata_ffill.to_csv(PLATA_DIR / \"misiones_plata_ffill.csv\", index=False)\n",
    "df_horario_completo.to_csv(PLATA_DIR / \"misiones_horario_completo.csv\", index=False)\n",
    "\n",
    "print(\"Archivos generados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "387836d4-c0de-457a-b4ff-7db2548ab541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            NOMBRE          FECHA_HORA      FECHA  HORA  TEMP   HUM     PNM     DD   FF  estacion_archivo\n",
      "0            OBERA 2024-06-01 09:00:00 2024-06-01   9.0  16.8  72.0  1020.4  320.0  4.0        20240601.0\n",
      "1            OBERA 2024-06-01 15:00:00 2024-06-01  15.0  22.8  84.0  1018.4   50.0  4.0        20240601.0\n",
      "2            OBERA 2024-06-01 21:00:00 2024-06-01  21.0  16.8  63.0  1017.6   50.0  4.0        20240601.0\n",
      "3            OBERA 2024-06-02 09:00:00        NaT   NaN   NaN   NaN     NaN    NaN  NaN               NaN\n",
      "4            OBERA 2024-06-02 15:00:00        NaT   NaN   NaN   NaN     NaN    NaN  NaN               NaN\n",
      "...            ...                 ...        ...   ...   ...   ...     ...    ...  ...               ...\n",
      "20140  IGUAZU AERO 2025-06-30 19:00:00 2025-06-30  19.0   7.5  93.0  1028.5  230.0  4.0        20250630.0\n",
      "20141  IGUAZU AERO 2025-06-30 20:00:00 2025-06-30  20.0   7.3  96.0  1028.9  230.0  4.0        20250630.0\n",
      "20142  IGUAZU AERO 2025-06-30 21:00:00 2025-06-30  21.0   6.8  93.0  1029.3    0.0  0.0        20250630.0\n",
      "20143  IGUAZU AERO 2025-06-30 22:00:00 2025-06-30  22.0   5.8  95.0  1029.7    0.0  0.0        20250630.0\n",
      "20144  IGUAZU AERO 2025-06-30 23:00:00 2025-06-30  23.0   5.0  95.0  1029.8    0.0  0.0        20250630.0\n",
      "\n",
      "[20145 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_horario_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b914b3-5333-417a-b3d7-4c406e1ee6ff",
   "metadata": {},
   "source": [
    "## Imputaci√≥n de datos faltantes basada en promedio entre d√≠as anterior y posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0270898-1317-4a53-ba81-43198b77cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores restantes faltantes por variable:\n",
      "TEMP    76\n",
      "HUM     76\n",
      "PNM     76\n",
      "DD      76\n",
      "FF      76\n",
      "dtype: int64\n",
      "\n",
      "Ejemplos de filas con valores a√∫n faltantes:\n",
      "    NOMBRE          FECHA_HORA FECHA  HORA  TEMP  HUM  PNM  DD  FF  estacion_archivo\n",
      "62   OBERA 2024-06-21 21:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "65   OBERA 2024-06-22 21:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "134  OBERA 2024-07-15 21:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "726  OBERA 2025-01-29 09:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "727  OBERA 2025-01-29 15:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n"
     ]
    }
   ],
   "source": [
    "# Variables a imputar\n",
    "variables_objetivo = ['TEMP', 'HUM', 'PNM', 'DD', 'FF']\n",
    "\n",
    "# Ordenar para asegurar coherencia\n",
    "df_horario_completo = df_horario_completo.sort_values(by=['NOMBRE', 'FECHA_HORA'])\n",
    "\n",
    "# Aplicar imputaci√≥n: promedio entre valores del d√≠a anterior y posterior para el mismo horario\n",
    "df_interp = df_horario_completo.copy()\n",
    "\n",
    "for var in variables_objetivo:\n",
    "    anterior = df_interp.groupby(['NOMBRE', df_interp['FECHA_HORA'].dt.hour])[var].shift(1)\n",
    "    posterior = df_interp.groupby(['NOMBRE', df_interp['FECHA_HORA'].dt.hour])[var].shift(-1)\n",
    "\n",
    "    # Calcular el promedio solo si ambos valores est√°n presentes\n",
    "    promedio = (anterior + posterior) / 2\n",
    "\n",
    "    imputado = df_interp[var].copy()\n",
    "    imputado = imputado.fillna(promedio)\n",
    "    imputado = imputado.fillna(anterior)   # Si no hay ambos, usar anterior\n",
    "    imputado = imputado.fillna(posterior)  # Si no hay anterior, usar posterior\n",
    "\n",
    "    df_interp[var] = imputado\n",
    "\n",
    "# Verificaci√≥n de imputaci√≥n final\n",
    "print(\"Valores restantes faltantes por variable:\")\n",
    "print(df_interp[variables_objetivo].isnull().sum())\n",
    "\n",
    "# Vista previa de algunos valores a√∫n faltantes (si existen)\n",
    "print(\"\\nEjemplos de filas con valores a√∫n faltantes:\")\n",
    "print(df_interp[df_interp[variables_objetivo].isnull().any(axis=1)].head())\n",
    "\n",
    "# Guardar archivo imputado si lo dese√°s\n",
    "# df_interp.to_csv(PLATA_DIR / \"misiones_horario_imputado.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "854f2576-1280-4ea7-9ec0-82a8fb298702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificaci√≥n de imputaci√≥n entre d√≠as vecinos:\n",
      "\n",
      "   NOMBRE          FECHA_HORA FECHA  HORA  TEMP  HUM  PNM  DD  FF  estacion_archivo\n",
      "4   OBERA 2024-06-02 15:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "25  OBERA 2024-06-09 15:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "46  OBERA 2024-06-16 15:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "66  OBERA 2024-06-23 09:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "67  OBERA 2024-06-23 15:00:00   NaT   NaN   NaN  NaN  NaN NaN NaN               NaN\n",
      "\n",
      "\n",
      "            NOMBRE          FECHA_HORA      FECHA  HORA  TEMP   HUM     PNM     DD   FF  estacion_archivo\n",
      "0            OBERA 2024-06-01 09:00:00 2024-06-01   9.0  16.8  72.0  1020.4  320.0  4.0        20240601.0\n",
      "1            OBERA 2024-06-01 15:00:00 2024-06-01  15.0  22.8  84.0  1018.4   50.0  4.0        20240601.0\n",
      "2            OBERA 2024-06-01 21:00:00 2024-06-01  21.0  16.8  63.0  1017.6   50.0  4.0        20240601.0\n",
      "3            OBERA 2024-06-02 09:00:00        NaT   NaN  16.8  63.0  1017.6   50.0  4.0               NaN\n",
      "4            OBERA 2024-06-02 15:00:00        NaT   NaN   NaN   NaN     NaN    NaN  NaN               NaN\n",
      "...            ...                 ...        ...   ...   ...   ...     ...    ...  ...               ...\n",
      "20140  IGUAZU AERO 2025-06-30 19:00:00 2025-06-30  19.0   7.5  93.0  1028.5  230.0  4.0        20250630.0\n",
      "20141  IGUAZU AERO 2025-06-30 20:00:00 2025-06-30  20.0   7.3  96.0  1028.9  230.0  4.0        20250630.0\n",
      "20142  IGUAZU AERO 2025-06-30 21:00:00 2025-06-30  21.0   6.8  93.0  1029.3    0.0  0.0        20250630.0\n",
      "20143  IGUAZU AERO 2025-06-30 22:00:00 2025-06-30  22.0   5.8  95.0  1029.7    0.0  0.0        20250630.0\n",
      "20144  IGUAZU AERO 2025-06-30 23:00:00 2025-06-30  23.0   5.0  95.0  1029.8    0.0  0.0        20250630.0\n",
      "\n",
      "[20145 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "variables_objetivo = ['TEMP', 'HUM', 'PNM', 'DD', 'FF']\n",
    "\n",
    "df_interp = df_horario_completo.copy()\n",
    "\n",
    "for var in variables_objetivo:\n",
    "    anterior = df_interp.groupby('NOMBRE')[var].shift(1)\n",
    "    posterior = df_interp.groupby('NOMBRE')[var].shift(-1)\n",
    "    \n",
    "    # Promedio cuando existen ambos\n",
    "    promedio = (anterior + posterior) / 2\n",
    "\n",
    "    # Asignar primero el promedio si ambos est√°n presentes\n",
    "    imputado = df_interp[var].copy()\n",
    "    imputado = imputado.fillna(promedio)\n",
    "\n",
    "    # Si sigue habiendo NaN, usar solo anterior si est√°\n",
    "    imputado = imputado.fillna(anterior)\n",
    "\n",
    "    # Si a√∫n hay NaN, usar solo posterior\n",
    "    imputado = imputado.fillna(posterior)\n",
    "\n",
    "    df_interp[var] = imputado\n",
    "\n",
    "# Verificar resultado de la imputaci√≥n\n",
    "print(\"Verificaci√≥n de imputaci√≥n entre d√≠as vecinos:\\n\")\n",
    "print(df_interp[df_interp[variables_objetivo].isnull().any(axis=1)].head())\n",
    "print(\"\\n\")\n",
    "print(df_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28817cb5-5790-4ddd-b1ba-fd715ff449e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
